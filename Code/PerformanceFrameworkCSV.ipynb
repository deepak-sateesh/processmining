{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deepak/opt/anaconda3/lib/python3.7/site-packages/pm4py/visualization/petrinet/__init__.py:20: UserWarning: please use the pm4py.visualization.petri_net package instead\n",
      "  warnings.warn(\"please use the pm4py.visualization.petri_net package instead\")\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'factory' from 'pm4py.visualization.petrinet' (/Users/deepak/opt/anaconda3/lib/python3.7/site-packages/pm4py/visualization/petrinet/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e3ecb3278d6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpm4py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualizer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdfg_visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpm4py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdfg_mining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpm4py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpetrinet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfactory\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpn_vis_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'factory' from 'pm4py.visualization.petrinet' (/Users/deepak/opt/anaconda3/lib/python3.7/site-packages/pm4py/visualization/petrinet/__init__.py)"
     ]
    }
   ],
   "source": [
    "#All the imports here\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.visualization.process_tree import visualizer as pt_visualizer\n",
    "from pm4py.objects.conversion.process_tree import converter as pt_converter\n",
    "from pm4py.algo.discovery.dfg import algorithm as dfg_discovery\n",
    "from pm4py.visualization.dfg import visualizer as dfg_visualization\n",
    "from pm4py.objects.conversion.dfg import converter as dfg_mining\n",
    "from pm4py.visualization.petrinet import factory as pn_vis_factory\n",
    "from collections import defaultdict \n",
    "import pandas as pd\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.objects.log.adapters.pandas import csv_import_adapter\n",
    "from pm4py.objects.conversion.log import factory as conversion_factory\n",
    "from pm4py.util import constants\n",
    "import math\n",
    "from datetime import date\n",
    "import datetime\n",
    "import numpy as np\n",
    "from pm4py.objects.log.util import sorting\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "from pm4py.statistics.traces.log import case_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_csv4 = pd.read_csv('Production_Data.csv', sep=',')\n",
    "log_csv4.rename(columns={'Activity': 'concept:name','Start Timestamp':'time:timestamp'}, inplace=True)\n",
    "log_csv4['time:timestamp'] =  pd.to_datetime(log_csv4['time:timestamp'] , format='%m/%d/%Y %H:%M:%S')\n",
    "log_csv4['Complete Timestamp'] =  pd.to_datetime(log_csv4['Complete Timestamp'] , format='%m/%d/%Y %H:%M:%S')\n",
    "parameters = {log_converter.Variants.TO_EVENT_LOG.value.Parameters.CASE_ID_KEY: 'Case ID'}\n",
    "event_log4 = log_converter.apply(log_csv4, parameters=parameters, variant=log_converter.Variants.TO_EVENT_LOG)\n",
    "event_log4 = sorting.sort_timestamp(event_log4,\"time:timestamp\", False)\n",
    "event_log4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_dict={}\n",
    "\n",
    "for case_index, case in enumerate(event_log4):\n",
    "        #print(\"\\n case index: %d  case id: %s\" % (case_index, case.attributes[\"concept:name\"]))\n",
    "        \n",
    "        for event_index, event in enumerate(case):\n",
    "            if(event[\"concept:name\"] in activities_dict.keys()): #and activities_dict[event[\"concept:name\"]] is not None):\n",
    "                #print(activities_dict[event[\"concept:name\"]])\n",
    "                activities_dict[event[\"concept:name\"]].append((case.attributes[\"concept:name\"],event_index, event[\"concept:name\"], event['Complete Timestamp']-event['time:timestamp']))\n",
    "            else:\n",
    "                activities_dict[event[\"concept:name\"]]=[(case.attributes[\"concept:name\"],event_index,event[\"concept:name\"],event['Complete Timestamp']-event['time:timestamp'])]\n",
    "\n",
    "#activities_dict\n",
    "average_dict={}\n",
    "for k,v in activities_dict.items():\n",
    "    i=0\n",
    "    for l in v:\n",
    "        i+=1\n",
    "        if(k in average_dict.keys()):\n",
    "            average_dict[k]=[average_dict[k][0]+l[3].total_seconds(), i]\n",
    "        else:\n",
    "            average_dict[k]=[l[3].total_seconds(),i]\n",
    "\n",
    "average_dict2={}\n",
    "for k,v in average_dict.items():\n",
    "    average_dict2[k]= v[0]/v[1]\n",
    "activities_dict.keys()  \n",
    "#print(activities_duration,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Detected Weakness Row','Case ID','Weakness Type (AF/PA)','Weakness ID','Weakness Origin', 'Weakness Time','Weakness Information','Weakness Measurement', 'Weakness Level']\n",
    "df=pd.DataFrame(columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_case_duration=case_statistics.get_median_caseduration (event_log4)\n",
    "median_case_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "case_description_durations=case_statistics.get_cases_description (event_log4)\n",
    "for k,v in case_description_durations.items():\n",
    "    row={cols[0]:k, cols[1]: k, cols[2]:'PA', cols[3]:'10',cols[4]:'Automatic detection',cols[5]:'',cols[6]:abs(v['caseDuration']-median_case_duration),cols[7]:'Distance from median case duration in seconds',cols[8]:'Case level'}\n",
    "    df=df.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case_index, case in enumerate(event_log4):\n",
    "        #print(\"\\n case index: %d  case id: %s\" % (case_index, case.attributes[\"concept:name\"]))\n",
    "        \n",
    "        for event_index, event in enumerate(case):\n",
    "            row={cols[0]:case.attributes[\"concept:name\"]+\"-> Event \"+str(event_index), cols[1]: case.attributes[\"concept:name\"], cols[2]:'PA', cols[3]:'11',cols[4]:'Automatic detection',cols[5]:event['time:timestamp'],cols[6]: datetime.timedelta( abs(average_dict2[event[\"concept:name\"]]-(event['Complete Timestamp']-event['time:timestamp']).total_seconds())),cols[7]:'Distance from average activity duration',cols[8]:'Activity level'}\n",
    "            df=df.append(row, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"PA_dataframe.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Weakness Information'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel(\"AF_dataframe.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_case_durations = case_statistics.get_all_casedurations(event_log4, parameters={\n",
    "    case_statistics.Parameters.TIMESTAMP_KEY: \"time:timestamp\"})\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_case_durations\n",
    "z=case_statistics.get_cases_description(event_log4)\n",
    "z['Case 12']['caseDuration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_case_duration = case_statistics.get_median_caseduration(event_log4, parameters={\n",
    "    case_statistics.Parameters.TIMESTAMP_KEY: \"time:timestamp\"\n",
    "})\n",
    "median_case_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.statistics.traces.log import case_arrival\n",
    "case_arrival_ratio = case_arrival.get_case_arrival_avg(event_log4, parameters={\n",
    "    case_arrival.Parameters.TIMESTAMP_KEY: \"time:timestamp\"})\n",
    "case_arrival_ratio      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.statistics.performance_spectrum import algorithm as performance_spectrum\n",
    "ps = performance_spectrum.apply(event_log4, [\"Final Inspection Q.C.\",\"Packing\"], parameters={performance_spectrum.Parameters.ACTIVITY_KEY: \"concept:name\",\n",
    "                                            performance_spectrum.Parameters.TIMESTAMP_KEY: \"time:timestamp\"})\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.log.util import interval_lifecycle\n",
    "enriched_log = interval_lifecycle.assign_lead_cycle_time(event_log4)\n",
    "enriched_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.statistics.sojourn_time.log import get as soj_time_get\n",
    "\n",
    "soj_time = soj_time_get.apply(event_log4, parameters={soj_time_get.Parameters.TIMESTAMP_KEY: \"time:timestamp\", soj_time_get.Parameters.START_TIMESTAMP_KEY: \"start_timestamp\"})\n",
    "print(soj_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py.algo.filtering.log.ltl  as ltl\n",
    "import pm4py.algo.filtering.pandas.ltl as ltl2\n",
    "import pandas as pd\n",
    "\n",
    "from pm4py.objects.conversion.log import factory as conversion_factory\n",
    "from pm4py.util import constants\n",
    "\n",
    "from pm4py.objects.log.util import sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_csv = pd.read_csv('Production_Data.csv', sep=',')\n",
    "log = conversion_factory.apply(log_csv, parameters={constants.PARAMETER_CONSTANT_CASEID_KEY: \"Case ID\",\n",
    "                                               constants.PARAMETER_CONSTANT_ACTIVITY_KEY: \"Activity\",\n",
    "                                                constants.PARAMETER_CONSTANT_START_TIMESTAMP_KEY:\"Start Timestamp\",\n",
    "                                                constants.PARAMETER_CONSTANT_RESOURCE_KEY:\"Resource\",\n",
    "                                                constants.PARAMETER_CONSTANT_TIMESTAMP_KEY:\"Complete Timestamp\"\n",
    "                                               })\n",
    "print(\"Log imported\\n\\n\\n\")\n",
    "\n",
    "logSorted = sorting.sort_timestamp(log,\"Start Timestamp\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "\n",
    "net, initial_marking, final_marking = inductive_miner.apply(logSorted)\n",
    "from pm4py.visualization.petrinet import visualizer as pn_visualizer\n",
    "gviz = pn_visualizer.apply(net, initial_marking, final_marking)\n",
    "pn_visualizer.view(gviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pm4py.objects.log.adapters.pandas import csv_import_adapter\n",
    "from pm4py.objects.conversion.log import factory as conversion_factory\n",
    "from pm4py.util import constants\n",
    "dataframe = csv_import_adapter.import_dataframe_from_path('Production_Data.csv', sep=\",\")\n",
    "log = conversion_factory.apply(dataframe, parameters={constants.PARAMETER_CONSTANT_CASEID_KEY: \"Case ID\",\n",
    "                                               constants.PARAMETER_CONSTANT_ACTIVITY_KEY: \"Activity\",\n",
    "                                                constants.PARAMETER_CONSTANT_START_TIMESTAMP_KEY:\"Start Timestamp\",\n",
    "                                                constants.PARAMETER_CONSTANT_RESOURCE_KEY:\"Resource\",\n",
    "                                                constants.PARAMETER_CONSTANT_TIMESTAMP_KEY:\"Complete Timestamp\"\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A='Packing'\n",
    "B='Final Inspection Q.C.'\n",
    "print(ltl.ltl_checker.A_eventually_B(log, A, B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltl2.ltl_checker.attr_value_different_persons(dataframe, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pm4py.algo.organizational_mining.roles import algorithm as roles_discovery\n",
    "roles = roles_discovery.apply(event_log4)\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
