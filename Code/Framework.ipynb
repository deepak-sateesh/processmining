{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the imports here\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "from pm4py.visualization.process_tree import visualizer as pt_visualizer\n",
    "from pm4py.objects.conversion.process_tree import converter as pt_converter\n",
    "from pm4py.algo.discovery.dfg import algorithm as dfg_discovery\n",
    "from pm4py.visualization.dfg import visualizer as dfg_visualization\n",
    "from pm4py.objects.conversion.dfg import converter as dfg_mining\n",
    "from pm4py.visualization.petrinet import factory as pn_vis_factory\n",
    "from collections import defaultdict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_log(log):\n",
    "    for case_index, case in enumerate(log):\n",
    "        print(\"\\n case index: %d  case id: %s\" % (case_index, case.attributes[\"concept:name\"]))\n",
    "        for event_index, event in enumerate(case):\n",
    "            print(\"event index: %d  event activity: %s\" % (event_index, event[\"concept:name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicate_events(x): \n",
    "    _size = len(x) \n",
    "    duplicate_list = [] \n",
    "    for i in range(_size): \n",
    "        k = i + 1\n",
    "        for j in range(k, _size): \n",
    "            if x[i] == x[j] and x[i] not in duplicate_list: \n",
    "                duplicate_list.append(x[i]) \n",
    "    return duplicate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class represents a directed graph using dfg \n",
    "class Graph: \n",
    "\n",
    "    def __init__(self,vertices): \n",
    "        self.V= vertices #No. of vertices \n",
    "        self.graph = defaultdict(list) # default dictionary to store graph \n",
    "\n",
    "    # function to add an edge to graph \n",
    "    def addEdge(self,u,v): \n",
    "        self.graph[u].append(v) \n",
    "    \n",
    "    # Use BFS to check path between s and d \n",
    "    def isReachable(self, s, d): \n",
    "        # Mark all the vertices as not visited \n",
    "        visited =[False]*(self.V) \n",
    "\n",
    "        # Create a queue for BFS \n",
    "        queue=[]\n",
    "\n",
    "        # Mark the source node as visited and enqueue it \n",
    "        queue.append(s) \n",
    "        visited[s] = True\n",
    "\n",
    "        while queue: \n",
    "\n",
    "            #Dequeue a vertex from queue \n",
    "            n = queue.pop(0) \n",
    "\n",
    "            # If this adjacent node is the destination node, \n",
    "            # then return true \n",
    "            if n == d: \n",
    "                return True\n",
    "\n",
    "            # Else, continue to do BFS \n",
    "            for i in self.graph[n]: \n",
    "                if visited[i] == False: \n",
    "                    queue.append(i) \n",
    "                    visited[i] = True\n",
    "        # If BFS is complete without visited d \n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_weakness(log, forbidden_sequence):\n",
    "    #Weakness 1: Duplicate or loop-> Same event repeating twice in the log\n",
    "    for case_index, case in enumerate(log):\n",
    "        print(\"\\n case index: %d  case id: %s\" % (case_index, case.attributes[\"concept:name\"]))\n",
    "        event_list=[]\n",
    "        \n",
    "        for event_index, event in enumerate(case):\n",
    "            print(\"event index: %d  event activity: %s\" % (event_index, event[\"concept:name\"]))\n",
    "            event_list.append(event[\"concept:name\"])\n",
    "            \n",
    "        print (\"The events which got repeated in the trace are\",find_duplicate_events(event_list))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    #Weakness 2: Find out if the forbidden sequence of events exists in the log\n",
    "    #applying the Directly follows graph discovery to get the sequence which are directly following each other\n",
    "    dfg_simple = dfg_discovery.apply(log)\n",
    "    violated_restrictions=[]#for directly following each other or indirectly following\n",
    "    for r in forbidden_sequence:\n",
    "        count=0\n",
    "        for d in dfg_simple.elements():\n",
    "            if(r==d):\n",
    "                count+=1\n",
    "                violated_restrictions.append((r,count))\n",
    "            #else if(r[0]==d[0]):\n",
    "            \n",
    "              \n",
    "                \n",
    "    print(\"Violated restrictions, Number of times violated: \",violated_restrictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8caf96f8c2124911b606bed2ba93bb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='parsing log, completed traces :: ', max=6.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There is a path from register request to decide\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a graph for the given dfg\n",
    "\n",
    "log = xes_importer.apply('running-example.xes')\n",
    "dfg_simple = dfg_discovery.apply(log)\n",
    "\n",
    "    \n",
    "g = Graph(len(list(dfg_simple.elements())))\n",
    "l=[]\n",
    "for t in dfg_simple.elements(): \n",
    "    for x in t: \n",
    "        l.append(x) \n",
    "l=list(set(l))#list mapping every element to a number\n",
    "for d in dfg_simple.elements():\n",
    "    g.addEdge(l.index(d[0]),l.index(d[1]))\n",
    "    \n",
    "\n",
    "u =l.index(\"register request\"); v = l.index(\"decide\")\n",
    "\n",
    "if g.isReachable(u, v): \n",
    "    print(\"There is a path from %s to %s\" % (l[u],l[v])) \n",
    "else : \n",
    "    print(\"There is no path from %s to %s\" % (l[u],l[v])) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6c5eafd69f4f4ea9030114ded6f6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='parsing log, completed traces :: ', max=6.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pm4py.objects.log.log.Trace'>\n",
      "<class 'pm4py.objects.log.log.Trace'>\n",
      "<class 'pm4py.objects.log.log.Trace'>\n",
      "<class 'pm4py.objects.log.log.Trace'>\n",
      "<class 'pm4py.objects.log.log.Trace'>\n",
      "<class 'pm4py.objects.log.log.Trace'>\n",
      "<class 'pm4py.objects.log.log.EventLog'>\n"
     ]
    }
   ],
   "source": [
    "log = xes_importer.apply('running-example.xes')\n",
    "dfg_simple = dfg_discovery.apply(log)\n",
    "\n",
    "for case_index, case in enumerate(log):\n",
    "    print(type(case))\n",
    "    #dfg_simple1 = dfg_discovery.apply(case)\n",
    "    \n",
    "\n",
    "print(type(log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.dfg.utils import dfg_utils\n",
    "from pm4py.objects.petri.petrinet import PetriNet, Marking\n",
    "from pm4py.objects.petri import utils as pn_util\n",
    "from enum import Enum\n",
    "from pm4py.util import exec_utils\n",
    "\n",
    "\n",
    "class Parameters(Enum):\n",
    "    START_ACTIVITIES = 'start_activities'\n",
    "    END_ACTIVITIES = 'end_activities'\n",
    "\n",
    "\n",
    "\n",
    "PARAM_KEY_START_ACTIVITIES = Parameters.START_ACTIVITIES\n",
    "PARAM_KEY_END_ACTIVITIES = Parameters.END_ACTIVITIES\n",
    "\n",
    "#obtain petrinet from dfg\n",
    "def obtain_petrinet_from_dfg(dfg, parameters=None):\n",
    "    \"\"\"\n",
    "    Applies the DFG mining on a given object (if it is a Pandas dataframe or a log, the DFG is calculated)\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    dfg\n",
    "        Object (DFG) (if it is a Pandas dataframe or a log, the DFG is calculated)\n",
    "    parameters\n",
    "        Parameters\n",
    "    \"\"\"\n",
    "    if parameters is None:\n",
    "        parameters = {}\n",
    "\n",
    "    dfg = dfg\n",
    "    start_activities = exec_utils.get_param_value(Parameters.START_ACTIVITIES, parameters,\n",
    "                                                  dfg_utils.infer_start_activities(\n",
    "                                                      dfg))\n",
    "    end_activities = exec_utils.get_param_value(Parameters.END_ACTIVITIES, parameters,\n",
    "                                                dfg_utils.infer_end_activities(dfg))\n",
    "    activities = dfg_utils.get_activities_from_dfg(dfg)\n",
    "\n",
    "    net = PetriNet(\"\")\n",
    "    im = Marking()\n",
    "    fm = Marking()\n",
    "\n",
    "    source = PetriNet.Place(\"source\")\n",
    "    net.places.add(source)\n",
    "    im[source] = 1\n",
    "    sink = PetriNet.Place(\"sink\")\n",
    "    net.places.add(sink)\n",
    "    fm[sink] = 1\n",
    "\n",
    "    places_corr = {}\n",
    "    index = 0\n",
    "\n",
    "    for act in activities:\n",
    "        places_corr[act] = PetriNet.Place(act)\n",
    "        net.places.add(places_corr[act])\n",
    "\n",
    "    for act in start_activities:\n",
    "        if act in places_corr:\n",
    "            index = index + 1\n",
    "            trans = PetriNet.Transition(act + \"_\" + str(index), act)\n",
    "            net.transitions.add(trans)\n",
    "            pn_util.add_arc_from_to(source, trans, net)\n",
    "            pn_util.add_arc_from_to(trans, places_corr[act], net)\n",
    "\n",
    "    for act in end_activities:\n",
    "        if act in places_corr:\n",
    "            index = index + 1\n",
    "            inv_trans = PetriNet.Transition(act + \"_\" + str(index), None)\n",
    "            net.transitions.add(inv_trans)\n",
    "            pn_util.add_arc_from_to(places_corr[act], inv_trans, net)\n",
    "            pn_util.add_arc_from_to(inv_trans, sink, net)\n",
    "\n",
    "    for el in dfg.keys():\n",
    "        act1 = el[0]\n",
    "        act2 = el[1]\n",
    "\n",
    "        index = index + 1\n",
    "        trans = PetriNet.Transition(act2 + \"_\" + str(index), act2)\n",
    "        net.transitions.add(trans)\n",
    "\n",
    "        pn_util.add_arc_from_to(places_corr[act1], trans, net)\n",
    "        pn_util.add_arc_from_to(trans, places_corr[act2], net)\n",
    "\n",
    "    return net, im, fm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unwanted_Activity(log, blacklist):\n",
    "    print(\"Unwanted activity function\")\n",
    "    for case_index, case in enumerate(log):\n",
    "        for event_index, event in enumerate(case):\n",
    "            if(event[\"concept:name\"] in blacklist):\n",
    "                print(\"Duplicate activity=> activity: %s -> case: %d  \" % (event[\"concept:name\"], case_index))\n",
    "    print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backloop(log):\n",
    "    print(\"Backloop function\")\n",
    "    for trace in log:\n",
    "        print(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Redundant_Activity(log):\n",
    "    print(\"Redundant_Activity function\")\n",
    "    for case_index, case in enumerate(log):\n",
    "        print(\"\\n case index: %d  case id: %s\" % (case_index, case.attributes[\"concept:name\"]))\n",
    "        event_list=[]\n",
    "        \n",
    "        for event_index, event in enumerate(case):\n",
    "            print(\"event index: %d  event activity: %s\" % (event_index, event[\"concept:name\"]))\n",
    "            event_list.append(event[\"concept:name\"])\n",
    "            \n",
    "        print (\"The events which got repeated in the trace are\",find_duplicate_events(event_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Interface():\n",
    "    print(\"Interface function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Switch_of_media():\n",
    "    print(\"Switch_of_media function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Idle_time():\n",
    "    print(\"Idle_time function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Variance_of_process_times():\n",
    "    print(\"Variance_of_process_times function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bottleneck():\n",
    "    print(\"Bottleneck function\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parallelizable_tasks():\n",
    "    print(\"Parallelizable_tasks function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Joint Master thesis:\n",
      "Modelling of production expertise to extend the data-driven analysis of process models\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1b9f96e3ce41419e41f5f09f2d5c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='parsing log, completed traces :: ', max=6.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Log imported\n",
      "\n",
      "\n",
      "\n",
      "Backloop function\n",
      "{'attributes': {'concept:name': '3', 'creator': 'Fluxicon Nitro'}, 'events': [{'concept:name': 'register request', 'org:resource': 'Pete', 'time:timestamp': datetime.datetime(2010, 12, 30, 14, 32, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600))), 'Activity': 'register request', 'Resource': 'Pete', 'Costs': '50'}, '..', {'concept:name': 'pay compensation', 'org:resource': 'Ellen', 'time:timestamp': datetime.datetime(2011, 1, 15, 10, 45, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600))), 'Activity': 'pay compensation', 'Resource': 'Ellen', 'Costs': '200'}]}\n",
      "{'attributes': {'concept:name': '2', 'creator': 'Fluxicon Nitro'}, 'events': [{'concept:name': 'register request', 'org:resource': 'Mike', 'time:timestamp': datetime.datetime(2010, 12, 30, 11, 32, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600))), 'Activity': 'register request', 'Resource': 'Mike', 'Costs': '50'}, '..', {'concept:name': 'pay compensation', 'org:resource': 'Ellen', 'time:timestamp': datetime.datetime(2011, 1, 8, 12, 5, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600))), 'Activity': 'pay compensation', 'Resource': 'Ellen', 'Costs': '200'}]}\n",
      "{'attributes': {'concept:name': '1', 'creator': 'Fluxicon Nitro'}, 'events': [{'concept:name': 'register request', 'org:resource': 'Pete', 'time:timestamp': datetime.datetime(2010, 12, 30, 11, 2, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600))), 'Activity': 'register request', 'Resource': 'Pete', 'Costs': '50'}, '..', {'concept:name': 'reject request', 'org:resource': 'Pete', 'time:timestamp': datetime.datetime(2011, 1, 7, 14, 24, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600))), 'Activity': 'reject request', 'Resource': 'Pete', 'Costs': '200'}]}\n",
      "{'attributes': {'concept:name': '6', 'creator': 'Fluxicon Nitro'}, 'events': [{'concept:name': 'register request', 'org:resource': 'Mike', 'time:timestamp': datetime.datetime(2011, 1, 6, 15, 2, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600))), 'Activity': 'register request', 'Resource': 'Mike', 'Costs': '50'}, '..', {'concept:name': 'pay compensation', 'org:resource': 'Mike', 'time:timestamp': datetime.datetime(2011, 1, 16, 11, 47, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600))), 'Activity': 'pay compensation', 'Resource': 'Mike', 'Costs': '200'}]}\n",
      "{'attributes': {'concept:name': '5', 'creator': 'Fluxicon Nitro'}, 'events': [{'concept:name': 'register request', 'org:resource': 'Ellen', 'time:timestamp': datetime.datetime(2011, 1, 6, 9, 2, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600))), 'Activity': 'register request', 'Resource': 'Ellen', 'Costs': '50'}, '..', {'concept:name': 'reject request', 'org:resource': 'Mike', 'time:timestamp': datetime.datetime(2011, 1, 24, 14, 56, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600))), 'Activity': 'reject request', 'Resource': 'Mike', 'Costs': '200'}]}\n",
      "{'attributes': {'concept:name': '4', 'creator': 'Fluxicon Nitro'}, 'events': [{'concept:name': 'register request', 'org:resource': 'Pete', 'time:timestamp': datetime.datetime(2011, 1, 6, 15, 2, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600))), 'Activity': 'register request', 'Resource': 'Pete', 'Costs': '50'}, '..', {'concept:name': 'reject request', 'org:resource': 'Ellen', 'time:timestamp': datetime.datetime(2011, 1, 12, 15, 44, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600))), 'Activity': 'reject request', 'Resource': 'Ellen', 'Costs': '200'}]}\n"
     ]
    }
   ],
   "source": [
    "# Defining main function \n",
    "def main(): \n",
    "    print(\"Welcome to Joint Master thesis:\\nModelling of production expertise to extend the data-driven analysis of process models\") \n",
    "    \n",
    "    '''#Import a log\n",
    "    log = xes_importer.apply('running-example.xes')\n",
    "    print(\"Log imported\")\n",
    "    \n",
    "    #Explore the log\n",
    "    #explore_log(log)\n",
    "    \n",
    "    #Define the forbidden sequence of events\n",
    "    #simple restriction which says you cannot decide without examining thoroughly \n",
    "    forbidden_sequence=[( 'decide','examine thoroughly')]\n",
    "    \n",
    "    #Find different kinds of weakness in the log\n",
    "    find_weakness(log, forbidden_sequence)\n",
    "    \n",
    "    #obtain_petrinet_from_dfg\n",
    "    dfg_simple = dfg_discovery.apply(log)\n",
    "    net, im, fm = obtain_petrinet_from_dfg(dfg_simple)\n",
    "\n",
    "    #Visualise the petrinet obtained\n",
    "    gviz = pn_vis_factory.apply(net, im, fm)\n",
    "    pn_vis_factory.view(gviz)'''\n",
    "    \n",
    "    log = xes_importer.apply('running-example.xes')\n",
    "    \n",
    "    print(\"Log imported\\n\\n\\n\")\n",
    "  \n",
    "    \n",
    "    '''print(\"Menu:\\n 1.Unwanted_Activity\\n 2.Backloop\\n 3.Redundant_Activity\\n 4.Interface\\n 5.Switch_of_media\\n 6.Idle_time\\n 7.Variance_of_process_times\\n 8.Bottleneck\\n 9.Parallelizable_tasks\\n 0.Exit \")\n",
    "    menuIndex = input(\"Enter the menu index:\")\n",
    "\n",
    "\n",
    "    if menuIndex==1:\n",
    "        blacklist=[ 'decide','examine thoroughly']\n",
    "        Unwanted_Activity(log, blacklist)\n",
    "        print(\"index is 1\")\n",
    "    elif menuIndex== 2:    \n",
    "        Backloop()\n",
    "\n",
    "    elif menuIndex== 3:\n",
    "        Redundant_Activity(log)\n",
    "\n",
    "    elif menuIndex== 4:\n",
    "        Interface()\n",
    "\n",
    "    elif menuIndex== 5:\n",
    "        Switch_of_media()\n",
    "\n",
    "    elif menuIndex== 6:\n",
    "        Idle_time()\n",
    "\n",
    "    elif menuIndex== 7:\n",
    "        Variance_of_process_times()\n",
    "\n",
    "    elif menuIndex== 8:\n",
    "        Bottleneck()\n",
    "\n",
    "    elif menuIndex== 9:\n",
    "        Parallelizable_tasks()\n",
    "    '''\n",
    "    \n",
    "    blacklist=[ 'decide','examine thoroughly']\n",
    "    #Unwanted_Activity(log, blacklist)\n",
    "    \n",
    "    Backloop(log)\n",
    "    \n",
    "    #Redundant_Activity(log) \n",
    "    \n",
    "    #Interface()\n",
    "    \n",
    "    #Switch_of_media()\n",
    "    \n",
    "    #Idle_time()\n",
    "    \n",
    "    #Variance_of_process_times()\n",
    "    \n",
    "    #Bottleneck()\n",
    "    \n",
    "    #Parallelizable_tasks()\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling main function\n",
    "if __name__==\"__main__\": \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
